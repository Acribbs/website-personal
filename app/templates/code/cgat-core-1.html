{% extends "base.html" %}
{% block home %}

<head>
<title>Computational Anatomy Blog</title>
<link href="/static/css/blog/style.css" rel="stylesheet">
<link href="/static/css/blog/bootstrap.css" rel="stylesheet" media="screen">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="stylesheet" type="" href="/static/css/custom.css"/>

<!---- start-smoth-scrolling---->
<script type="text/javascript" src="/static/js/blog/move-top.js"></script>
<script type="text/javascript" src="/static/js/blog/easing.js"></script>
<script type="text/javascript">
			jQuery(document).ready(function($) {
				$(".scroll").click(function(event){		
					event.preventDefault();
					$('html,body').animate({scrollTop:$(this.hash).offset().top},1000);
				});
			});
		</script>
<!--start-smoth-scrolling-->
</head>
	<div class="single">
		<div class="container">
				<div class="single-top">
						<a href="#"><img class="img-responsive" alt="CGAT-core" src="/static/img/CGAT_logo.png" alt=" " style="height:40%;width:40%;margin-left:20%;"></a>
					<div class=" single-grid">
						<h3>Cgat-core</h3>				
							<ul class="blog-ic">
								<li><a href="#"><span> <i  class="glyphicon glyphicon-user"> </i>Adam Cribbs</span> </a> </li>
		  						 <li><span><i class="glyphicon glyphicon-time"> </i>March 13, 2019</span></li>	
		  						 <!-- Need to change the icons to font awsome ones -->	  						 	
		  					</ul>
<div class="single-blog">	  						

<p>In this post I will detail how easy and quickly it is to build computational pipeines using CGAT-core</p> 

<p>Recently we released the Computational Genomics Analysis Toolkit core library <a href="">(CGAT-core)</a> with accompanying <a href="">documentation</a> on how to
use the code to build effective computational workflows.</p>

<p>The reson that I like CGAT-core so much (and obviously im biased) is that you can build simple
stand alone workflows, as well as complex pipelines, and even meta pipelines (pipeline that control pipelines) extremely quickly. The reason that CGAT-core scales so well is that
pipelines effectively become commandline parsable scripts, with everything written into one file. Therefore, you dont have the hassle of writing complex separate rules
like other workflow managers require</p> 

<p>CGAT-core extends the functionality of CGAT-ruffus, which uses the python decorator functionality to control the flow of a pipeline.</p>

<p>In order to begin writing a pipeline you need to write (or copy and paste) a few helper functions so CGAT-core can work effectively.</p>

<h4><b>Import statements</h4></b> 

<p>To import the functionality of CGAT-core we usually import the following statements:</p>
<pre>
	<code>
		from ruffus import *
		from cgatcore import pipeline as P
		import cgatcore.experiment as E
		import cgatcore.iotools as iotools
	</code>
</pre>

<p>The two most important imports are pipeline and ruffus, which will control flow, logging, execution to a cluster and more. The 
experiment import had utility functions that make building pipelines easier. Additionally, we also have other modules such as database (which has database utilities),
csvutils (helper utilities for working with csv and tsv files) and tables (helper functions for manipulating tables) to name a few.</p>

<h4><b>Config parser</h4></b>

<p>If you would like to modify the functionality of the pipeline without having to re-write large sections then code to
help with parsing configurable yml files is useful</p>

<pre>
	<code>
	P.get_parameters(
    	["%s/pipeline.yml" % os.path.splitext(__file__)[0],
     	"../pipeline.yml",
     	"pipeline.yml"])
	</code>
</pre>

<h4><b>Commandline parser</h4></b>

<pre>
	<code>
	def main(argv=None):
    if argv is None:
        argv = sys.argv
    P.main(argv)


	if __name__ == "__main__":
    sys.exit(P.main(sys.argv))
	</code>
</pre>

<p>This converts your code into a CGAT-core commandline parsable workflow</p>

<p>Now we are ready to write our code. As a simple script I am interested in concatenating bam files together then
indexing them. The code can be written as follows:</p>

<h4><b>The code</h4></b>

<pre>
	<code>
	<font color="blue"># We use a collate ruffus function because we want to collate all inputs into
	# the correct outputs - please see ruffus documentation for more details on each decorator</font>
	
	@collate(*.bam,
         regex("%s.bam" % PARAMS["merge_pattern_input"].strip()),
         r"%s.bam" % (PARAMS["merge_pattern_output"].strip()))
	
	<font color="blue"># We use the information within the PARAMS dict (imported from pipeline.yml (more on that in a bit)
	# using the commandline parser)</font>
	
	def merge_bams(infiles, outfile):
    	'''merge bam files based on the merge pattern.'''

    	infiles = list(infiles)
    	
    	<font color="blue"># We want to turn the list of files into a string separated by a space</font>
    	
    	infiles = " ".join(infiles)

		<font color="blue"># The statement is represents the commanline statement that will be exectured.
		# we will use the cat function to conbine al of our files together and output them as one file.</font>
   		
   		statement = '''cat %(infiles)s > %(outfile)s'''

		<font color="blue"># the run statement will execture your job locally or across a cluster (More on that in a bit).</font>
    	
    	P.run(statement)
    
    @transform(merge_bams,
    			suffix(".bam"),
    			.bam.bai)
    def index_bams(infile, outfile):
    	'''will index bam files following merging'''
    
    	statement = "samtools index %(infile)s %(outfile)s"
    	
    	P.run(statement)
    	
	</code>
	
<h4><b>Parameter file</h4></b>

<p>In order to change the functionality of the pipeline without modifying any of the hard code we will generate a pipeline.yml
file containing the following code:</p>

<pre>
	<code>
	merge: 
    	pattern_input: '(\S+)_L\d+'
    	pattern_output: '\1'
	</code>
</pre>

<p>This will allow us to use regular expressions to pick up and group the files together. For example is
samples are split over different lanes and called [name]_L001 and [name]_L002 then the regular expression will
merge the name across all lanes. The parameters you add into the yml file will be converted to merge_pattern_input
an can be accessed within the pipeline using the PARAMS dictionary using PARAMS['merge_pattern_input'].</p>

<h4><b>Ordering all the files correctly</h4></b>
 
 <p>So far you should have two files, one containing the code and the other the pipeline.yml file. The code file should be named
 pipeline_[name].py for example pipeline_catbams.py and the pipeline.yml added into a filer with the same name pipeline_catbams/.
 Now you can begin to execute your pipeline:</p>

<h4><b>Run your pipeline</h4></b>
 
 
</pre>
</div>						
</div>
</div>	

	
	


{% endblock %}






